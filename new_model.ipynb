{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import transformers\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import AutoTokenizer, GPT2Tokenizer, AutoConfig, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 309\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 78\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_from_disk(\"./sample_dataset\")\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs length: 2\n",
      "Input chunk lengths: {'overflowing_tokens': [[287, 281, 15452, 1182, 198, 20451, 278, 514, 1363, 198, 198, 40, 2911, 314, 1239, 4425, 345, 198, 34456, 340, 1239, 5645, 198, 40, 1549, 1239, 2513, 11424, 25418, 3530, 757, 198, 2504, 338, 262, 17855, 2612, 9032, 640, 714, 1239, 47618, 198, 40, 1549, 1239, 2513, 11424, 25418, 3530, 757, 198, 1870, 5156, 11, 314, 651, 21619, 1431, 416, 703, 198, 1212, 1748, 26557, 534, 1438, 198, 1870, 5156, 11, 314, 1101, 523, 22144, 286, 198, 361, 345, 1683, 2513, 1497, 198, 40, 1549, 1239, 2513, 11424, 25418, 3530, 757, 198, 40, 1549, 1239, 2513, 11424, 25418, 3530, 757, 198, 198, 11209, 28507, 826, 1280, 11, 23608, 1633, 198, 41, 8317, 705, 744, 616, 12450, 318, 12431, 198, 1135, 12012, 262, 29424, 319, 11424, 25418, 3530, 198, 13579, 273, 1096, 262, 1126, 4730, 287, 262, 4314, 198, 7282, 618, 356, 547, 2657, 27476, 11, 2712, 1830, 198, 40, 1807, 345, 547, 3756, 502, 319, 198, 40, 11856, 616, 11668, 11, 1364, 11424, 25418, 3530, 198, 8421, 345, 772, 2993, 314, 373, 3750, 198, 198, 1537, 788, 345, 1444, 11, 3751, 534, 1021, 198, 40, 2900, 1088, 878, 314, 2277, 262, 13275, 198, 20245, 319, 262, 9753, 11, 345, 290, 314, 198, 198, 40, 2911, 314, 1239, 4425, 345, 198, 34456, 340, 1239, 5645, 198, 40, 1549, 1239, 2513, 11424, 25418, 3530, 757, 198, 2504, 338, 262, 17855, 2612, 9032, 640, 714, 1239, 47618, 198, 40, 1549, 1239, 2513, 11424, 25418, 3530, 757, 198, 1870, 5156, 11, 314, 651, 21619, 1431, 416, 703, 198, 1212, 1748, 26557, 534, 1438, 198, 1870, 5156, 11, 314, 1101, 523, 22144, 286, 198, 361, 345, 1683, 2513, 1497, 198, 40, 1549, 1239, 2513, 11424, 25418, 3530, 757, 198, 40, 1549, 1239, 2513, 11424, 25418, 3530, 757, 198, 198, 1639, 1745, 616, 1021, 319, 262, 4675, 198, 35963, 502, 736, 284, 326, 7962, 198, 40630, 2084, 11, 356, 547, 655, 2641, 198, 33, 533, 5898, 287, 262, 9592, 198, 38318, 445, 649, 33875, 198, 2504, 2627, 616, 5737, 11, 6004, 198, 198, 40, 2911, 314, 1239, 4425, 345, 198, 40, 1549, 1239, 2513, 11424, 25418, 3530, 757, 198, 5812, 11, 1239, 757, 198, 1870, 5156, 11, 314, 651, 21619, 1431, 416, 703, 198, 1212, 1748, 26557, 534, 1438, 198, 1870, 5156, 11, 314, 1101, 523, 22144, 286, 198, 1532, 345, 1683, 2513, 1497, 198, 40, 1549, 1239, 2513, 11424, 25418, 3530, 757, 198, 40, 1549, 1239, 2513, 11424, 25418, 3530, 757, 198, 198, 40, 836, 470, 18869, 4425, 345, 357, 34456, 340, 1239, 5645, 8, 198, 40, 1549, 1239, 2513, 11424, 25418, 3530, 757, 198, 40, 836, 470, 18869, 4425, 345, 357, 10995, 8, 198, 198, 1, 40, 5602, 257, 1295, 319, 11424, 25418, 3530, 1, 198, 40, 531, 27793, 287, 262, 1097], [644, 750, 314, 466, 198, 8128, 340, 460, 470, 307, 356, 821, 1541, 832, 198, 11633, 345, 3677, 502, 503, 329, 257, 9192, 198, 3260, 345, 2714, 502, 318, 326, 655, 644, 345, 466, 198, 2061, 750, 345, 761, 422, 502, 198, 24446, 502, 198, 198, 12322, 640, 284, 18996, 314, 760, 198, 2504, 661, 1487, 511, 9017, 198, 1537, 326, 373, 1223, 314, 16555, 345, 561, 910, 198, 2514, 616, 1986, 198, 1537, 345, 1057, 1497, 198, 198, 23722, 345, 1560, 502, 644, 750, 314, 466, 198, 8128, 340, 460, 470, 307, 356, 821, 1541, 832, 198, 11633, 345, 3677, 502, 503, 329, 257, 9192, 198, 3260, 345, 2714, 502, 318, 326, 655, 644, 345, 466, 198, 2061, 750, 345, 761, 422, 502, 198, 24446, 502, 198, 198, 1532, 314, 550, 257, 1738, 393, 257, 2829, 24829, 198, 36534, 772, 257, 6486, 198, 10995, 9425, 198, 198, 24446, 502, 644, 750, 314, 466, 198, 3856, 682, 5156, 6451, 356, 821, 1541, 832, 198, 11633, 345, 3677, 502, 503, 329, 257, 9192, 198, 3260, 345, 2714, 502, 318, 326, 655, 644, 345, 466, 198, 2061, 750, 345, 761, 422, 502, 198, 24446, 502, 198, 1870, 1560, 502, 198, 198, 46, 2238, 1219, 9425, 198, 24446, 502, 198, 24446, 2185]], 'num_truncated_tokens': [458, 209], 'input_ids': [[1135, 547, 287, 262, 736, 24073, 198, 6187, 2954, 319, 1223, 7387, 198, 817, 272, 262, 11758, 287, 262, 2318, 198, 1, 40, 5602, 257, 1295, 319, 11424, 25418, 3530, 1, 198, 40, 531, 27793, 287, 262, 1097, 198, 1135, 547, 257, 4713, 2443, 319, 262, 6915, 198, 37, 4509, 287, 262, 698, 2283, 355, 356, 467, 198, 1722, 611, 262, 4675, 7588, 6235], [1026, 373, 1223, 588, 257, 2818, 923, 284, 198, 1212, 1842, 7415, 475, 783, 508, 389, 345, 198, 40, 1807, 314, 2993, 198, 7120, 2951, 703, 284, 760, 284, 804, 826, 832, 502, 198, 1026, 338, 588, 345, 16453, 262, 2456, 345, 25029, 284, 502, 198, 2990, 6304, 470, 2081, 198, 1026, 338, 588, 340, 2492, 470, 345, 198, 198, 23722, 345, 1560, 502]], 'length': [64, 64], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "context_length = 64\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")\n",
    "outputs = tokenizer(\n",
    "    dataset[\"train\"][:2][\"text\"],\n",
    "    truncation=True,\n",
    "    max_length=context_length,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_length=True,\n",
    ")\n",
    "print(f\"Input IDs length: {len(outputs['input_ids'])}\")\n",
    "print(f\"Input chunk lengths: {(outputs)}\")\n",
    "# print(f\"Chunk mapping: {outputs['overflow_to_sample_mapping']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Someone struck a match against the night\n",
      "All I could see was you and I\n",
      "It was captivating\n",
      "A perfect little dream inside my head\n",
      "And then reality crept in\n",
      "And erased it\n",
      "For a while I thought that I could hold you\n",
      "But you were just a temporary high\n",
      "\n",
      "Firefly\n",
      "You\n",
      "Someone struck a match against the night\n",
      "All I could see was you and I\n",
      "It was captivating\n",
      "A perfect little dream inside my head\n",
      "And then reality crept in\n",
      "And erased it\n",
      "For a while I thought that I could hold you\n",
      "But you were just a temporary high\n",
      "\n",
      "Firefly\n",
      "You\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# def tokenize(element):\n",
    "#     outputs = tokenizer(\n",
    "#         element[\"text\"],\n",
    "#         truncation=True,\n",
    "#         max_length=context_length,\n",
    "#         return_overflowing_tokens=True,\n",
    "#         return_length=True,\n",
    "#     )\n",
    "#     input_batch = []\n",
    "#     for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "#         if length == context_length:\n",
    "#             input_batch.append(input_ids)\n",
    "#     return {\"input_ids\": input_batch}\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=64)\n",
    "\n",
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "# block_size = int(tokenizer.model_max_length / 4)\n",
    "block_size = 64\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=1,\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(lm_datasets['train'][65]['input_ids']))\n",
    "print(tokenizer.decode(lm_datasets['train'][65]['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained('distilgpt2', vocab_size=len(tokenizer), n_ctx=context_length, bos_token_id=tokenizer.bos_token_id, eos_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"output/model-v4/checkpoint-4340/\")\n",
    "\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([5, 64])\n",
      "attention_mask shape: torch.Size([5, 64])\n",
      "labels shape: torch.Size([5, 64])\n"
     ]
    }
   ],
   "source": [
    "out = data_collator([lm_datasets[\"train\"][i] for i in range(5)])\n",
    "for key in out:\n",
    "    print(f\"{key} shape: {out[key].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTORCH_ENABLE_MPS_FALLBACK=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhavya/projects/hugging-face-playground/output/model-generator is already a clone of https://huggingface.co/BhavyaMuni/model-generator. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/lyrics/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import wandb\n",
    "import random\n",
    "seed_data = random.randint(0,2**32-1)\n",
    "%set_env PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"output/model-generator\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_steps=1,\n",
    "    seed=seed_data,\n",
    "    do_eval=True,\n",
    "    eval_steps=1,\n",
    "    logging_steps=5,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=1.372e-4,\n",
    "    push_to_hub=True,\n",
    "    report_to='wandb',\n",
    "    resume_from_checkpoint=True,\n",
    "    load_best_model_at_end=True,\n",
    "    use_mps_device=True\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"test\"],\n",
    ")\n",
    "\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "train_dataloader = trainer.get_train_dataloader()\n",
    "num_train_steps = len(train_dataloader)\n",
    "trainer.create_optimizer_and_scheduler(num_train_steps)\n",
    "trainer.lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "      trainer.optimizer,\n",
    "      num_warmup_steps=0,\n",
    "      num_training_steps=num_train_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 5/390 [00:02<02:38,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.3589, 'learning_rate': 0.00013171058983499535, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 10/390 [00:04<01:57,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5818, 'learning_rate': 0.00011612089065075853, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 15/390 [00:05<01:50,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4577, 'learning_rate': 9.292589525111794e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 20/390 [00:07<01:47,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2686, 'learning_rate': 6.583775650849414e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 25/390 [00:08<01:46,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4678, 'learning_rate': 3.9191690287750474e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 30/390 [00:10<01:45,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4316, 'learning_rate': 1.725216267546246e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 35/390 [00:11<01:44,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.115, 'learning_rate': 3.53040008242582e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 39/390 [00:12<01:41,  3.46it/s]\n",
      " 10%|█         | 39/390 [00:13<01:41,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0731794834136963, 'eval_runtime': 0.533, 'eval_samples_per_second': 146.35, 'eval_steps_per_second': 18.763, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 40/390 [00:21<17:05,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0991, 'learning_rate': 2.2244866199319123e-07, 'epoch': 1.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 45/390 [00:23<04:13,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2541, 'learning_rate': 7.857716640189785e-06, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 50/390 [00:24<02:05,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0404, 'learning_rate': 2.5214247234157134e-05, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 55/390 [00:26<01:42,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1311, 'learning_rate': 4.9514281975331363e-05, 'epoch': 1.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 60/390 [00:27<01:37,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9329, 'learning_rate': 7.686881626551516e-05, 'epoch': 1.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 65/390 [00:29<01:34,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8844, 'learning_rate': 0.00010290000000000001, 'epoch': 1.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 70/390 [00:30<01:32,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9633, 'learning_rate': 0.0001234417735694802, 'epoch': 1.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 75/390 [00:32<01:31,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6055, 'learning_rate': 0.00013520660867542716, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 78/390 [00:33<01:28,  3.52it/s]\n",
      " 20%|██        | 78/390 [00:33<01:28,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.039727210998535, 'eval_runtime': 0.5293, 'eval_samples_per_second': 147.372, 'eval_steps_per_second': 18.894, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 80/390 [00:35<03:52,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7318, 'learning_rate': 0.00013631164801696085, 'epoch': 2.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 85/390 [00:37<01:52,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7169, 'learning_rate': 0.00012658003986830435, 'epoch': 2.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 90/390 [00:38<01:31,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7808, 'learning_rate': 0.00010756924162575734, 'epoch': 2.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 95/390 [00:40<01:26,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3581, 'learning_rate': 8.232176259303673e-05, 'epoch': 2.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 100/390 [00:41<01:25,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.644, 'learning_rate': 5.4878237406963316e-05, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 105/390 [00:43<01:22,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4609, 'learning_rate': 2.9630758374242683e-05, 'epoch': 2.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 110/390 [00:44<01:20,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7294, 'learning_rate': 1.0619960131695668e-05, 'epoch': 2.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 115/390 [00:46<01:19,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6177, 'learning_rate': 8.883519830391712e-07, 'epoch': 2.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 117/390 [00:46<01:13,  3.70it/s]\n",
      " 30%|███       | 117/390 [00:47<01:13,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0282094478607178, 'eval_runtime': 0.533, 'eval_samples_per_second': 146.34, 'eval_steps_per_second': 18.761, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 120/390 [00:49<02:38,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3499, 'learning_rate': 1.9933913245728396e-06, 'epoch': 3.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 125/390 [00:50<01:30,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3168, 'learning_rate': 1.3758226430519834e-05, 'epoch': 3.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 130/390 [00:52<01:18,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2746, 'learning_rate': 3.4300000000000014e-05, 'epoch': 3.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 135/390 [00:53<01:14,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5159, 'learning_rate': 6.033118373448485e-05, 'epoch': 3.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 140/390 [00:55<01:13,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2588, 'learning_rate': 8.768571802466866e-05, 'epoch': 3.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 145/390 [00:56<01:11,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7555, 'learning_rate': 0.00011198575276584287, 'epoch': 3.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 150/390 [00:58<01:10,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.478, 'learning_rate': 0.00012934228335981018, 'epoch': 3.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 155/390 [00:59<01:07,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3965, 'learning_rate': 0.00013697755133800678, 'epoch': 3.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 156/390 [00:59<01:03,  3.70it/s]\n",
      " 40%|████      | 156/390 [01:00<01:03,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.069936752319336, 'eval_runtime': 0.5316, 'eval_samples_per_second': 146.717, 'eval_steps_per_second': 18.81, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 160/390 [01:03<01:56,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4282, 'learning_rate': 0.00013366959991757425, 'epoch': 4.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 165/390 [01:04<01:13,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1554, 'learning_rate': 0.00011994783732453755, 'epoch': 4.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 170/390 [01:06<01:05,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3892, 'learning_rate': 9.800830971224965e-05, 'epoch': 4.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 175/390 [01:07<01:03,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1545, 'learning_rate': 7.13622434915059e-05, 'epoch': 4.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 180/390 [01:09<01:01,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3164, 'learning_rate': 4.42741047488822e-05, 'epoch': 4.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 185/390 [01:10<00:59,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1536, 'learning_rate': 2.1079109349241507e-05, 'epoch': 4.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 190/390 [01:11<00:58,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9767, 'learning_rate': 5.4894101650047195e-06, 'epoch': 4.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 195/390 [01:13<00:53,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1936, 'learning_rate': 0.0, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 195/390 [01:13<00:53,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1293678283691406, 'eval_runtime': 0.5311, 'eval_samples_per_second': 146.864, 'eval_steps_per_second': 18.829, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 200/390 [01:17<01:24,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0904, 'learning_rate': 5.489410165004689e-06, 'epoch': 5.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 205/390 [01:18<00:58,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0566, 'learning_rate': 2.1079109349241446e-05, 'epoch': 5.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 210/390 [01:19<00:53,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1135, 'learning_rate': 4.4274104748882125e-05, 'epoch': 5.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 215/390 [01:21<00:51,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9506, 'learning_rate': 7.136224349150582e-05, 'epoch': 5.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 220/390 [01:22<00:51,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0318, 'learning_rate': 9.800830971224957e-05, 'epoch': 5.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 225/390 [01:24<00:51,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0393, 'learning_rate': 0.00011994783732453749, 'epoch': 5.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 230/390 [01:25<00:47,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0771, 'learning_rate': 0.0001336695999175742, 'epoch': 5.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 234/390 [01:27<00:46,  3.37it/s]\n",
      " 60%|██████    | 234/390 [01:27<00:46,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1790242195129395, 'eval_runtime': 0.5556, 'eval_samples_per_second': 140.389, 'eval_steps_per_second': 17.999, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 235/390 [01:38<09:29,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2626, 'learning_rate': 0.0001369775513380068, 'epoch': 6.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 240/390 [01:40<02:12,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9211, 'learning_rate': 0.00012934228335981018, 'epoch': 6.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 245/390 [01:42<01:03,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0232, 'learning_rate': 0.00011198575276584294, 'epoch': 6.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 250/390 [01:43<00:45,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8734, 'learning_rate': 8.768571802466861e-05, 'epoch': 6.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 255/390 [01:45<00:40,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8892, 'learning_rate': 6.033118373448493e-05, 'epoch': 6.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 260/390 [01:46<00:39,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0948, 'learning_rate': 3.429999999999998e-05, 'epoch': 6.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 265/390 [01:48<00:39,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0702, 'learning_rate': 1.375822643051988e-05, 'epoch': 6.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 270/390 [01:49<00:39,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9385, 'learning_rate': 1.9933913245728244e-06, 'epoch': 6.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 273/390 [01:50<00:37,  3.13it/s]\n",
      " 70%|███████   | 273/390 [01:51<00:37,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.237593650817871, 'eval_runtime': 0.7133, 'eval_samples_per_second': 109.345, 'eval_steps_per_second': 14.019, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 275/390 [01:54<01:41,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7394, 'learning_rate': 8.883519830391636e-07, 'epoch': 7.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 280/390 [01:55<00:45,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.821, 'learning_rate': 1.0619960131695684e-05, 'epoch': 7.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 285/390 [01:57<00:34,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9581, 'learning_rate': 2.963075837424261e-05, 'epoch': 7.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 290/390 [01:59<00:34,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7309, 'learning_rate': 5.4878237406963356e-05, 'epoch': 7.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 295/390 [02:00<00:29,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8473, 'learning_rate': 8.232176259303652e-05, 'epoch': 7.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 300/390 [02:02<00:27,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9024, 'learning_rate': 0.00010756924162575728, 'epoch': 7.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 305/390 [02:03<00:25,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8353, 'learning_rate': 0.00012658003986830424, 'epoch': 7.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 310/390 [02:05<00:25,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7569, 'learning_rate': 0.00013631164801696083, 'epoch': 7.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 312/390 [02:05<00:23,  3.35it/s]\n",
      " 80%|████████  | 312/390 [02:06<00:23,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3039562702178955, 'eval_runtime': 0.5476, 'eval_samples_per_second': 142.449, 'eval_steps_per_second': 18.263, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 315/390 [02:09<00:50,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.882, 'learning_rate': 0.0001352066086754272, 'epoch': 8.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 320/390 [02:10<00:26,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7951, 'learning_rate': 0.00012344177356948035, 'epoch': 8.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 325/390 [02:12<00:22,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7124, 'learning_rate': 0.00010289999999999993, 'epoch': 8.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 330/390 [02:14<00:19,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.704, 'learning_rate': 7.68688162655152e-05, 'epoch': 8.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 335/390 [02:15<00:18,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8006, 'learning_rate': 4.95142819753315e-05, 'epoch': 8.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 340/390 [02:17<00:16,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7725, 'learning_rate': 2.521424723415734e-05, 'epoch': 8.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 345/390 [02:18<00:13,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6942, 'learning_rate': 7.857716640189763e-06, 'epoch': 8.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 350/390 [02:20<00:12,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7553, 'learning_rate': 2.2244866199319883e-07, 'epoch': 8.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 351/390 [02:20<00:11,  3.41it/s]\n",
      " 90%|█████████ | 351/390 [02:21<00:11,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.347101926803589, 'eval_runtime': 0.6001, 'eval_samples_per_second': 129.972, 'eval_steps_per_second': 16.663, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 355/390 [02:24<00:19,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7052, 'learning_rate': 3.530400082425759e-06, 'epoch': 9.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 360/390 [02:25<00:10,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6258, 'learning_rate': 1.7252162675462267e-05, 'epoch': 9.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 365/390 [02:27<00:07,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5787, 'learning_rate': 3.9191690287750535e-05, 'epoch': 9.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 370/390 [02:28<00:06,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5684, 'learning_rate': 6.583775650849406e-05, 'epoch': 9.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 375/390 [02:30<00:04,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6645, 'learning_rate': 9.292589525111775e-05, 'epoch': 9.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 380/390 [02:31<00:03,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7005, 'learning_rate': 0.00011612089065075828, 'epoch': 9.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 385/390 [02:33<00:01,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7337, 'learning_rate': 0.00013171058983499535, 'epoch': 9.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [02:34<00:00,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7012, 'learning_rate': 0.0001372, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 390/390 [02:35<00:00,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3939199447631836, 'eval_runtime': 0.5437, 'eval_samples_per_second': 143.464, 'eval_steps_per_second': 18.393, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [02:37<00:00,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 157.4999, 'train_samples_per_second': 19.619, 'train_steps_per_second': 2.476, 'train_loss': 1.2969607848387499, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=390, training_loss=1.2969607848387499, metrics={'train_runtime': 157.4999, 'train_samples_per_second': 19.619, 'train_steps_per_second': 2.476, 'train_loss': 1.2969607848387499, 'epoch': 10.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def post_process(output_sequences):\n",
    "    predictions = []\n",
    "    generated_sequences = []\n",
    "\n",
    "    max_repeat = 2\n",
    "\n",
    "    # decode prediction\n",
    "    for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n",
    "        generated_sequence = generated_sequence.tolist()\n",
    "        text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True, skip_special_tokens=True)\n",
    "        generated_sequences.append(text.strip())\n",
    "                    \n",
    "    for i, g in enumerate(generated_sequences):\n",
    "        res = str(g).replace('\\n\\n\\n', '\\n').replace('\\n\\n', '\\n')\n",
    "        lines = res.split('\\n')\n",
    "        # print(lines)\n",
    "        i = max_repeat\n",
    "        while i != len(lines):\n",
    "          remove_count = 0\n",
    "          for index in range(0, max_repeat):\n",
    "            # print(i - index - 1, i - index)\n",
    "            if lines[i - index - 1] == lines[i - index]:\n",
    "              remove_count += 1\n",
    "          if remove_count == max_repeat:\n",
    "            lines.pop(i)\n",
    "            i -= 1\n",
    "          else:\n",
    "            i += 1\n",
    "        predictions.append('\\n'.join(lines))\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Hey there!!!\\nWhat a waste\\nI was\\nI was there\\nI remember you dancing before your eyes went wild\\nOn backroads at night\\nWhen I passed the pictures around of you\\nAnd your little eyelids flutter cause it's glow\\nIn the winter\\nBut I watched it rain\\nOh, it's just so quiet in the world\\nI was watching you\\nIt was just you, I was watching you\\nI watched you\\nI\", \"Hey there \\nWell I guess I wished on a plane I thought was a star\\nHey, yeah\\nYeah\\nI guess I liked that\\nYou liked that\\nWell I guess you liked that\\nThat little black dress\\nI wore before you went and let me down\\nThere you stand now, ten feet tall\\nEulogize me\\nCause I'm the tallest building we had ever been\\nI was in the tallest building I was in the whole scene\", \"Hey there \\nI hope you see me\\nLookin' like a face in the crowd\\nI hope you see me\\nOoh look what you made me do\\nLook like a face in the crowd\\nI'd give up forever for\\nI'd give up forever to touch you\\nBut I'm so sorry\\nI don't see\\n you here\\nI'd meet you here\\nThe last straw\\nIf it doesn't come back\\nI'd lie\\nIf\", \"Hey there \\nYou are on my mind\\nI wonder if you know me\\nAnd you made me stay\\nThe first wave\\nYou're showing off new\\nnew\\nlook\\nT-ah try this time around\\nI'm feeling like I just lost a friend\\nDon't be fooled by the rocks that I got I'm still, I'm still Jenny from the block Used to have a little, now I have a lot\\nI have a lot\\nI have a lot,\", \"Hey there \\nNow I'm standing on a street\\nLooks like I lost the war\\nI thought\\nAll too well\\nIs here I am\\nIn a new town\\nI thought you might be home somehow\\nCan you believe it\\nMy dear\\nI love you to the moon\\nWhen the sun shines\\nDown\\nI come back each time\\nI wanna know how much it hurts to be right\\nSince you're gone\\nAnd I wanna know how much it hurts to feel\", 'Hey there \", someone told me\\nI\\'ma stayin\\' at my parents\\' house\\nI remember tears streaming down your face\\nI cry and I walk through the door with you\\nThe air is cold but something \\'bout it felt like home somehow and\\nWhile I been having too much to drink tonight\\nMy saltbox house on the lake now looks like a war\\nI guess you should\\'ve told her you\\nI guess I liked that\\nI liked that', \"Hey there hey hey\\nWe were sitting in the kitchen in the refrigerator\\nAfter having been having a hard time adjusting\\nI made up my mind\\nI told myself I was fine\\nBut what a waste\\nI told myself\\nI was fine\\nBut not fine\\nI was walking fast through the traffic lights\\nIn the traffic lights\\nIt's not fair that I'm not there\\nAnd I'm dead wrong when it hurts\\nBaby,\", \"Hey there \\nIn your life, yeah you should be there\\nI want to tell my friends, how's it feel to be the center\\nWhere all your potential is\\nAnd I need you\\nI'd be smart to walk away\\nBut you're quicksand\\nYou're quicksand\\nYou're the one\\nYou should be in the conversation\\nTalk to my friends, talk to me\\nTalk to me\\nTalk to me\\nTalk\", 'Hey there \\nI guess I liked that\\nI liked that\\nAnd when you fell hard you took a step back\\nLet me remind you why I was lost in the lights\\nIn backyards\\nEulogizing him would cut me to the core\\nHe said \"let\\'s get out of this town.\"\\nHe said don\\'t walk in here\"\\nHe said don\\'t hate big cities, look now I wanna make up\\nYou got me alone\\nBut', \"Hey there ㅋㅋㅋ\\nI used to watch him sleep\\nBut you got that old smile\\nIt's killing me to see you\\nI wonder why, when you leave me I just think\\n(Oh yeah, you're right, I want it)\\n(Ooh, you're right, I want it)\\nI was believing in you\\n(Oh yeah, you're right, I want it)\\n(Ooh, you're right, I want it)\\n(\", \"Hey there \\nI didn't mean to piss off your friends\\nI just thought\\nDidn't matter what you say\\nI said\\nI ain't tryna mess with the flow\\nBut I've seen\\nThat flow\\nTried to turn the page\\nAnd baby it's all funny now\\nI didn't mean\\nYou didn't mean it\\nAnd baby you didn't mean it\\nI don't wanna take it too hard\", \"Hey there \\nHey there you are\\nYou found meeeeee\\nI was reminiscing when I first saw you\\nOh yeah\\nYou found meeeeee\\nI was reminiscing when I first saw you\\nI second you see meeeeee\\nEvery night for so long baby\\nYou're filling in my hole\\nTo make life work so harder and faster\\nBut do you still wanna be there\\nBut do you remember what you put me through\\nSomebody else gave me your\", \"Hey there \\nIf there's a plane, you know that I'm about to blow up\\nBut I'm right here\\nIn my heart\\nA small town, with a feeling somethin' like\\nA summer wonderland\\nThe small town looks like a dream\\nThe moment I meet you in the rain\\nI'm dreaming big\\nYou got a suitcase full of stuff you'd give out\\nAnd hide it's real,\\nBaby, you got a car\\nAnd all you\", \"Hey there \\nI can't una\\nYou know I wanna make\\n(You know I wanna make)\\n(I wanna make)\\n(I wanna make)\\n(We gonna make)\\n(He's so tall and handsome as hell)\\nI can still see him\\nLooking at me like I am an expert at\\nI'm not trying\\nI'm\\nI'm just a wrinkle in your new pattern\\nWe might get used to it\\nYou could make your\", \"Hey there \\nAnd meet someone new\\nYou gotta believe them\\nIf you dream of a white Christmas\\nWhere all those bright city lights almost killed my light\\nIf you dream of a blue sky\\nWhere all those bright city lights almost killed my light\\nI hate to think about the city at all\\nSo goodbye, it's been a long time\\nI hate to think about the city at all\\nTo be wrong, right, right, right, right here\\nSo goodbye\", \"Hey there \\nI'm just gonna tell you\\nI ain't been through it all\\nSo why am I wasting time\\nCause all I can breathe is your face\\nI'm so mad I might tell you that\\nI don't need your love\\nAnd I wonder why\\nWhy am I wasting my time\\nCause time\\nI might know you\\nI love me\\nIf you love me then I love me\\nAnd I wonder why\\nYou'd\", \"Hey there ㅋㅋㅋI've always been a bit reckless\\nYou tried to calm me down, but I...I just wanted to tell you..\\nI'm not your typical princess\\nWhen you're everything to me\\nI'd be breaking down and coming undone\\nI'd be breaking every single heart of you tonight\\nThe tricky thing is tonight we got issues\\nAnd I'll say this week\\nI'm not the one that's thinking\\nStood on the cliffside screaming\\nI don\", \"Hey there ________\\nYou are in my room ________\\nYou're in my room\\nLike a movie\\nLike a sixties' trend\\nFor the first time\\nI had a chance\\nThey'd tell me the shape of your hair\\nBut I felt so euphoric\\nWith the sun shining bright\\nAnd right after\\nI started\\nA few mistakes ago\\nI was in your sights\\nHaving watched\\nThe world\\nBurning brighter than the sun\\nNow you look\", \"Hey there \\nI didn't warn ya\\nDon't stray\\nLeave!\\nI'm\\ncoming home\\nLike a scared little girl\\nI think I'm\\nI like a cannonball\\nI'm just pretending I'm not scared\\nI'm just pretending I'm not scared\\nI'm standing here\\nIn a crowded room\\nI'm feeling like I don't know what I would do\\nOh my, what a perfect start\\nHow's life\", \"Hey there \\n\\xa0\\nI knew you were trouble when you walked in\\nI knew you were trouble when you walked in\\nBack at night, when I\\nI was riding on my skateboard\\nYour little hands wrapped around my finger\\nFaded blue paint\\nAnd I used to roll my eyes\\nI'd roll your eyes at you like the road\\nBut now I'm so far away and I'm down\\nIn the middle of the woods\\nWith no idea what to say\", \"Hey there \\nWhat I was thinking\\nWould end with a little help from a little snow\\nWhoa, you deserve nothing more\\nYou are somebody that I don't know\\nAnd when you reach where you started\\nIt's hard to see a picture drop\\nWhile you're still up doing it\\nIt's nice to know you're on my guard\\nBut down here, I know\\nI know\\nYou ain't the one\\nTo break down and cry\", \"Hey there!!!\\nI just seen you there in plain sight\\nI don't know how to be something you miss\\nAnd I can feel time moving\\nTime\\nAll this time I didn't know\\nI used to be on your side\\nFighting with the world was boxing with me\\nIt's boxing with me\\nI've always been a bit reckless\\nI'm not your typical princess\\nI'm fine, just a bit of a mess\\nTrying to play stupid games\", \"Hey there  and you've got your big coat on\\nBut there ain't nothing bout 'cause\\nYou think I'm the best I am to tell you\\nI can't believe you had been here all along\\nAnd I might, if you could see\\nBut if you could see\\nThat little black dress\\nI wore in my blue jeans\\nOh, what a shame\\nI wore at the party\\nI wore at the fairytale\\nIn back\", \"Hey there \\nI bet this time you're not home \\nI bet your window is rolled down and your hair is pulled back\\nI bet you got no idea you're getting down on about me\\nAbout me\\nI'm pretty sure we fell apart\\nI'm here on the kitchen floor\\nI love you to the moon and back\\nAnd I got nothing to regret\\nNow I'm thinking about you even if I don't know\\nSo I've been having a hard time adjusting\", \"Hey there  before you go\\nThe holidays linger like lingerie\\nWith no coats on me\\nI wear high heels\\nWhile I do I know what I feel like\\nYou look like the next to my daddy\\nI'll be like her when she's ten and she's fifteen\\nI'll be the mirrorball\\nThat's when the sun goes down\\nI think I hit you late and find myself at your window\\nStood there so hard\\nAnd you're late at night,\", \"Hey there \\xa0\\nIt's a sad picture\\nThere you stand \\xa0\\nIt's a sad picture\\nThere you stand \\nIt's a sad picture\\nBut if it all sticks now\\nI can't take it back\\nI've been having issues\\n(chorus:)\\nHeaven can't help me here\\nHeaven can't help me here\\nI'd be the one that\", \"Hey there \\nWhen your face is lookin' like an angel\\nTo kiss in the rain\\nDon't be afraid to cry\\nDon't be afraid to say yes\\nDon't be afraid to walk away\\nI want\\nTo tell the world how good it is\\nTo walk away\\nBut I'm afraid to tell the world how fast I can go\\nI just wanna be your little beauty queen\\nI'm gonna make you mine\\nMy t-shirt is gonna take you home\", \"Hey there \\nI was riding on my skateboard when I passed you\\nIn your view\\nI never wanted\\nto be alone\\nSo I punched a hole in the roof so high\\nAnd ran out into the city on foot\\nWith one of these acorns\\nGrowing up and falling through\\nLike the big bad ones\\nIt's a new dawn, the shape of your name\\nThe shape of your name has changed,\\nYou guessed it was the shape of your name\", \"Hey there \\nThe world's so much older\\nA mysterious way about you dear\\nHaving kissed goodbye\\nTo be mine\\nIt's a sad picture, the final blow hits you\\nWhoa\\nThe world's so young\\nWhoa\\nYou've seen this video\\nYou know that I wanna be with you\\nAnd I'm right here with you\\nWith you\\nHey, hey how's life?\\nHey, hey where's your daddy?\\nI was watching\", \"Hey there (Wondering) How could we be so happy?\\nI met Bobby on the boardwalk and was having a hard time getting the words right\\nOn the back of my mind\\nOn the sleepless night when I'm sitting here and you try\\nI think you know that\\nYou try to stay away and you try to walk away\\nBut what's happening is happening\\nIn the middle of the night, when I'm in this dream\\nAnd I feel like walking away\", 'Hey there?\"\\nI heard he said\\nHey there is something\\nGonna climb up again\\nHe says\\n\"I\\'m not gonna touch you\"\\nI\\'m not gonna touch you\"\\nHe says\\nBut can you feel this magic in the air?\\nWhen everything\\'s made to look bad?\\nAnd when everything\\'s made to look good,\\nEverything\\'s made to look right\\nSo baby, now I know I can run to you', \"Hey there \\nIt feels like a perfect night\\nThe lights are so bright\\nI'll put them to good use\\nThis place is too crowded\\nI'm waiting on you\\nI'm waiting on you\\nHow's life?\\n\\nSo it's a sad picture\\nIn the living\\nI didn't know what I wanted\\nYou ended up here\\nAnd you've got a beautiful boy\\nHe's beautiful\\nAnd he's smart and handsome\\nHe\", \"Hey there \\n\\xa0I'm always up when needed\\nI'm always waiting\\nI'm always waiting\\nAnd right when I was just old plywood\\nSkipping down the street\\nTo meet someone new\\nI'm sick and tired of your attitude\\nStaring at the break and go\\nAnd think if I'm coming home\\nAnd that's all I know\\n\\nI'm just a kid\\nI'm just a toy\\nI'm walking\", \"Hey there __________________\\nI love you\\nI love you\\nYou can hear it in the silence, the silence\\nYou can feel it on the way home, way home\\nI love you with the lights out\\nAnd now I'm wide awake\\nYou're singing in stations all night, trying to read\\nStaring at the window, trying to write me a song\\nWe're down in the trees, we're lying on the street\", \"Hey there  \\nI'm trying to read you like a\\nDinner With your hands in my pockets\\nYou made me think I was a dreamer\\nBut I realized you kinda stick around\\nKeep your eyes open\\nThis could be one of them\\nI know from the look on your face\\nIt could be one of them\\nI'd give all of us\\nTill you tore us apart this is coming apart\\nYou can't keep it going\\nYou can\", \"Hey there \\nI love you\\nAnd sometimes when our pieces fall apart, I hold onto you\\nAnd my waves meet your shore\\nWhen we broke up a year and a half ago\\nI won't give in\\nAll that time\\nWe always wanted again\\nAnd I'd give all I have\\nA chance\\nHe's so tall and handsome as hell\\nHe's so bad but he does it so well\\nHe's so bad but he does it so well\\nAnd when\", \"Hey there \\nIt all comes down to this one\\nI know I've been a while\\nI've been spending the last 8 months wondering why\\nI get no leads in my tracks\\nI wonder if you knew, I wonder if you know, if you know, if you know\\n\\nI wonder if you know, if you know\\nI love the simple things\\nI just know\\nI'll tell you why\\nI love the simple things\", \"Hey there \\nHe got a girlfriend, she's older than us\\nShe lives just a little, she lives just a little\\nJust a little out of reach, she lives just a little\\nWe found wonderland\\nIn wonderland, in wonderland, in wonderland\\nI met Bobby on a west bound train\\nGot a long list of ex lovers to tell them\\nWho you gonna think you are\\nIs this guy\\nYou know that I'm gonna marry me\", \"Hey there \\nThe highway don't care\\nI don't like to be in this world anymore\\nI don't like to be in this way\\nI don't wanna look at anything else now\\nI'm not the kind of girl\\nLike I don't wanna dance if I'm not\\nLike I don't wanna talk about anything else\\nI don't wanna talk about anything else\\nI'm not the kind of girl\\nShe wasn't cut down by the sun last night\\nBut if\", \"Hey there \\nIt was a fairytale\\nI wore a dress\\nIn summer air\\nFaded blue jeans\\nT-shirt\\nI wore a dress\\nIn summer air\\nYeah it's true, rumours fly\\nOn\\nThis slope I've been getting so confused\\nIt's made for me\\nJust a little valley by the river where we'd ride\\nBefore I found a man with a fire\\nIn the sky\\nThat's what the hell we thought\"]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Hey there \"\n",
    "tokenized_prompt = tokenizer(prompt, return_tensors='pt', add_special_tokens=False).input_ids.to(trainer.args.device)\n",
    "output = trainer.model.generate(\n",
    "                        input_ids=tokenized_prompt,\n",
    "                        max_length=100,\n",
    "                        min_length=60,\n",
    "                        temperature=float(1),\n",
    "                        top_p=float(0.95),\n",
    "                        top_k=int(50),\n",
    "                        do_sample=True,\n",
    "                        repetition_penalty=1,\n",
    "                        num_return_sequences=40\n",
    "                        )\n",
    "\n",
    "print(post_process(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n",
      "Upload file pytorch_model.bin: 320MB [02:34, 4.84MB/s]                            To https://huggingface.co/BhavyaMuni/model-generator\n",
      "   94d8184..a638e07  main -> main\n",
      "\n",
      "Upload file pytorch_model.bin: 100%|██████████| 318M/318M [02:35<00:00, 2.15MB/s]\n",
      "Upload file training_args.bin: 100%|██████████| 4.30k/4.30k [02:35<00:00, 28.3B/s]\n",
      "To https://huggingface.co/BhavyaMuni/model-generator\n",
      "   a638e07..e23e1db  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/BhavyaMuni/model-generator/commit/a638e076a80f154ef8053473b9d58c29a4acd27d'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer.push_to_hub(\"trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78bf3dfab2409d0de93bc88a070d69a2c578003fb5569f9b0436b24fbd75556d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
